{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_user_score(row):\n",
    "    try:\n",
    "        if (row['click'] > -1 and row['basket'] > -1 and row['order'] > -1):\n",
    "            return (row['click'] * 1) + (row['basket'] * 10) + (row['order'] * 20)\n",
    "        return 0\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = pd.read_csv('transactions.csv', sep=\"|\", error_bad_lines=False)\n",
    "transactions_df['user_score'] = transactions_df.apply(map_user_score, axis=1)\n",
    "transactions_df = transactions_df.drop(columns=['sessionID', 'click', 'basket', 'order'])\n",
    "transactions_df = transactions_df.groupby('itemID').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_score(item):\n",
    "    try:\n",
    "        score = int(transactions_df.loc[item.itemID])\n",
    "        item.score = score\n",
    "        return item\n",
    "    except:\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():    \n",
    "    items_data = pd.read_csv('items.csv', sep=\"|\", error_bad_lines=False)\n",
    "    items_data = items_data.dropna(how='any') # change later\n",
    "    items_data['title'] = items_data['title'].str.lower()\n",
    "#     return items_data.drop_duplicates(subset='title', keep='first').head(40000)\n",
    "    items_data = items_data.drop_duplicates(subset='title', keep='first')\n",
    "#     items_data = items_data.loc[items_data[\"subtopics\"] != '[]']\n",
    "    items_data['score'] = 0\n",
    "\n",
    "    items_data = items_data.apply(get_item_score, axis=1)\n",
    "    items_data = items_data.reset_index(drop=True)\n",
    "    return items_data.head(40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data_result = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data_result = get_data_result.drop('itemID', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data_result.to_csv('books.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_data(data):\n",
    "    data_recommend = data.drop(columns=['title', 'publisher', 'subtopics'])\n",
    "    # we use author, publisher, main topic\n",
    "    data_recommend['combine'] = data_recommend[data_recommend.columns[0:2]].apply(\n",
    "                                                                         lambda x: ' '.join(x.dropna().astype(str)),axis=1)\n",
    "    data_recommend = data_recommend.drop(columns=['author', 'main topic'])\n",
    "    data_recommend['combine'] = data_recommend['combine'].replace({\"[^A-Za-z0-9 ]+\": \"\"}, regex=True)\n",
    "    return data_recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = combine_data(get_data_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>combine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Janey Louise Jones YFB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145</td>\n",
       "      <td>Wiebke Krabbe AGZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>367</td>\n",
       "      <td>Victoria Aveyard YFH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97</td>\n",
       "      <td>Elizabeth Golding WFTM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>112</td>\n",
       "      <td>J R Ward FMR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score                 combine\n",
       "0      3  Janey Louise Jones YFB\n",
       "1    145       Wiebke Krabbe AGZ\n",
       "2    367    Victoria Aveyard YFH\n",
       "3     97  Elizabeth Golding WFTM\n",
       "4    112            J R Ward FMR"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data_combine, data_plot):\n",
    "    count = CountVectorizer(stop_words='english')\n",
    "    count_matrix = count.fit_transform(data_combine['combine'])\n",
    "\n",
    "#     tfidf = TfidfVectorizer(stop_words='english')\n",
    "#     tfidf_matrix = tfidf.fit_transform(data_plot['subtopics'])\n",
    "\n",
    "#     combine_sparse = sp.hstack([count_matrix, tfidf_matrix], format='csr')\n",
    "\n",
    "    count2 = CountVectorizer(stop_words='english')\n",
    "    count_matrix2 = count2.fit_transform(data_plot['subtopics'].apply(lambda x: x[1:-1].replace(',', ' ')))\n",
    "    combine_sparse = sp.hstack([count_matrix, count_matrix2], format='csr')\n",
    "    \n",
    "    cosine_sim = cosine_similarity(combine_sparse, combine_sparse)\n",
    "\n",
    "#     cosine_sim = cosine_similarity(count_matrix)\n",
    "    \n",
    "    return cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_books(title, data, combine, transform):\n",
    "\n",
    "    indices = pd.Series(data.index, index = data['title'])\n",
    "    index = indices[title]\n",
    "\n",
    "    sim_scores = list(enumerate(transform[index]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:6]\n",
    "    \n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "#     print(book_indices)\n",
    "\n",
    "    book_id = data['itemID'].iloc[book_indices]\n",
    "    book_title = data['title'].iloc[book_indices]\n",
    "    book_author = data['author'].iloc[book_indices]\n",
    "    book_main_topic = data['main topic'].iloc[book_indices]\n",
    "    book_scores = data['score'].iloc[book_indices]\n",
    "    book_subtopics = data['subtopics'].iloc[book_indices]\n",
    "\n",
    "    recommendation_data = pd.DataFrame(columns=['Book_Id','Name','Author'])\n",
    "\n",
    "    recommendation_data['Book_Id'] = book_id\n",
    "    recommendation_data['Name'] = book_title\n",
    "    recommendation_data['Author'] = book_author\n",
    "    recommendation_data['Main Topic'] = book_main_topic\n",
    "    recommendation_data['Subtopics'] = book_subtopics\n",
    "    recommendation_data['Score'] = book_scores\n",
    "    \n",
    "    return recommendation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(book_name, find_book, combine_result, transform_result, sort_by_score=False):\n",
    "    book_name = book_name.lower()\n",
    "    \n",
    "    #find_book = get_data()\n",
    "    #combine_result = combine_data(find_book)\n",
    "    #transform_result = transform_data(combine_result,find_book)\n",
    "    \n",
    "    if book_name not in find_book['title'].unique():\n",
    "        return 'Book not in Database'\n",
    "    \n",
    "    else:\n",
    "        recommendations = recommend_books(book_name, find_book, combine_result, transform_result)\n",
    "        if (sort_by_score):\n",
    "            return recommendations.sort_values(by=['Score'], ascending=False)\n",
    "        else:\n",
    "            return recommendations\n",
    "#             return recommendations.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_book = get_data()\n",
    "combine_result = combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_result = transform_data(combine_result, find_book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savez_compressed\n",
    "import os\n",
    "for i in range(len(transform_result)):\n",
    "    filename = f\"transform_result_{i}.npz\"\n",
    "    savez_compressed(os.path.abspath('./transform_results/' + filename), transform_result[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'transform_result.npz'\n",
    "# from numpy import load\n",
    "# loaded = load(filename)\n",
    "# transform_result = loaded['arr_0']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
